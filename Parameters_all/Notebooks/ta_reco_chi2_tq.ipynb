{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mq = get_measured_ldf(mask, qs) / **Det_Area**   ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = '../../data_01_24.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 64\n",
    "\n",
    "with h5.File(h5f,'r') as hf:\n",
    "    times_flat = hf['dt_bunlde'][:num,:,:,4:5]*1e6 # in mks\n",
    "    times_diff = hf['dt_bunlde'][:num,:,:,5:6]*1e6 # in mks\n",
    "    mask_in = hf['dt_bunlde'][:num,:,:,6:7]\n",
    "    real_coords = hf['dt_bunlde'][:num,:,:,:3]*1.2 # in km\n",
    "    qs_in = hf['dt_bunlde'][:num,:,:,3:4]\n",
    "    ev_params = hf['recos'][:num]\n",
    "    \n",
    "mask_qs = tf.where( tf.math.logical_and(mask_in>0, qs_in>0), 1., 0. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set c=1, time in mks, distance in km\n",
    "time2dist = tf.constant(0.299792458, dtype=tf.float32)\n",
    "\n",
    "times_flat *= time2dist\n",
    "times_diff *= time2dist\n",
    "\n",
    "times_reg = times_flat + times_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shower core, initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_max = np.amax(qs_in)*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_core_sat(qs, coords, mask, mask_qs, fill_val):\n",
    "    \n",
    "    qs = tf.where( mask==mask_qs, qs, [fill_val] )\n",
    "    return tf.math.reduce_sum( qs*coords, axis=(1,2), keepdims=True ) / tf.math.reduce_sum(qs, axis=(1,2), keepdims=True)\n",
    "      \n",
    "def get_r_core(qs, coords):\n",
    "    return tf.math.reduce_sum( qs*coords, axis=(1,2), keepdims=True ) / tf.math.reduce_sum(qs, axis=(1,2), keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_core_sat_0 = get_r_core_sat(qs_in, real_coords[:,:,:,:2], mask_in, mask_qs, q_max) # (bs,1,1,2)\n",
    "r_core_0 = get_r_core(qs_in, real_coords[:,:,:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print((r_core_0-r_core_sat_0)[:3,0,0,:]) # small difference since saturated detectors are near the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.30211398  0.26573572]\n",
      " [-0.03845022 -0.01971256]\n",
      " [ 0.00260762 -0.22016773]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.30211398  0.26573572]\n",
      " [-0.03845022 -0.01971256]\n",
      " [ 0.00260762 -0.22016773]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(r_core_sat_0[:3,0,0,:])\n",
    "print(r_core_0[:3,0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare matricies to solve\n",
    "def make_matrix(coords, times_reg, mask):\n",
    "    \n",
    "    # matrix for dL/db\n",
    "    hs = tf.ones((num,6,6,1)) # to make (x_1,x_2) -> (x_1,x_2,1), to account for b\n",
    "    coords_ext = mask*tf.concat( (coords,hs), axis=-1 ) # (bs,6,6,3)\n",
    "    matrix_b = tf.expand_dims( tf.math.reduce_sum( coords_ext, axis=(1,2) ), axis=-1 ) # (bs,3,1)\n",
    "    times = mask*times_reg # (bs,6,6,1)\n",
    "    rhs_b = tf.math.reduce_sum( times, axis=(1,2) ) # (bs,1)\n",
    "    \n",
    "    # matrix for dL/da\n",
    "    coords_mul = tf.expand_dims( coords_ext, axis=-1) * tf.expand_dims( coords, axis=-2)\n",
    "    matrix_a = tf.math.reduce_sum( coords_mul, axis=(1,2) ) # (bs,3,2)\n",
    "    ts_mul = times * coords\n",
    "    rhs_a = tf.math.reduce_sum( ts_mul, axis=(1,2) )\n",
    "    \n",
    "    matrix = tf.concat((matrix_b,matrix_a), axis=-1)\n",
    "    rhs = tf.expand_dims( tf.concat((rhs_b,rhs_a), axis=-1), axis=-1 )\n",
    "    \n",
    "    return matrix, rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_solve(matrix, rhs):\n",
    "    \n",
    "    sol_flat = tf.linalg.solve( matrix, rhs, adjoint=True )[:,:,0]\n",
    "    print(sol_flat)\n",
    "    t0 = sol_flat[:,2]\n",
    "    # extract parameters\n",
    "    n_z = 1. - tf.math.reduce_sum(sol_flat[:,:2]*sol_flat[:,:2], axis=1)\n",
    "    n_z = tf.where( n_z>0, tf.math.sqrt( n_z ), 0. ) # some configurations yield front moving faster than light\n",
    "    theta_flat = tf.math.acos( n_z )\n",
    "    phi_flat = tf.math.atan2( -sol_flat[:,1], -sol_flat[:,0] )\n",
    "    \n",
    "    return theta_flat, phi_flat, t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.94365281e+05 -5.27451625e+05  1.93256453e+05]\n",
      " [ 5.83730938e+05  3.06786328e+04  1.51503234e+05]\n",
      " [ 1.69319781e+05 -2.25759277e+04  2.28110234e+05]\n",
      " [-1.34247375e+05  1.02333766e+05  4.41834000e+05]\n",
      " [-3.41419812e+05  5.38652893e+02  2.27203266e+05]\n",
      " [ 1.19045469e+05  1.61439014e+03  2.04585109e+05]\n",
      " [-6.62905000e+04 -4.71816211e+04  1.27207484e+05]\n",
      " [-3.31798156e+05 -4.95958867e+04  2.92045094e+05]\n",
      " [ 1.76714258e+04  2.91321625e+05  2.61974906e+05]\n",
      " [ 2.02916172e+05 -7.86245859e+04  3.16326719e+05]\n",
      " [-5.65876500e+05  3.72428281e+05  2.97586750e+05]\n",
      " [-4.31444531e+04 -4.78346031e+05  4.02160812e+05]\n",
      " [-6.27121938e+05  1.26379164e+05  2.43055547e+05]\n",
      " [-1.18420219e+05  4.88306688e+05  1.95091875e+05]\n",
      " [ 7.59783125e+04 -3.03305156e+05  1.22048852e+05]\n",
      " [ 4.69426875e+05 -1.10562266e+05  2.61070906e+05]\n",
      " [-3.36520875e+05  3.16676281e+05  3.41831844e+05]\n",
      " [ 4.54308219e+05  3.47532125e+05  2.34211828e+05]\n",
      " [-5.29753062e+05 -2.67297241e+03  1.59693000e+05]\n",
      " [ 5.28639188e+05 -1.94012281e+05  2.30415906e+05]\n",
      " [ 2.41772328e+05 -2.04775938e+05  2.15291969e+05]\n",
      " [-5.32454312e+05 -1.31616963e+04  2.42726734e+05]\n",
      " [ 4.72529500e+05 -4.66498945e+04  3.52783188e+05]\n",
      " [ 4.78903438e+05 -1.81097500e+05  2.20291609e+05]\n",
      " [-4.42667938e+05  2.34550609e+05  2.25302984e+05]\n",
      " [ 4.17480094e+05 -1.82172438e+05  1.77336828e+05]\n",
      " [-4.83467969e+05 -3.21093906e+05  1.56870047e+05]\n",
      " [-1.50725000e+05  3.90171406e+05  1.53477016e+05]\n",
      " [-3.73365125e+05  3.02708844e+05  2.23527906e+05]\n",
      " [ 2.46937422e+04 -4.82826594e+05  2.47254062e+05]\n",
      " [ 1.71470328e+05 -5.01854656e+05  1.74381234e+05]\n",
      " [-1.14985523e+05  3.61341281e+05  3.41162844e+05]\n",
      " [-6.38922062e+05 -5.03104639e+03  9.43567969e+04]\n",
      " [-1.06774453e+05 -2.08748078e+05  2.67884281e+05]\n",
      " [-7.60298984e+04 -1.71038453e+05  2.74876344e+05]\n",
      " [-3.37534844e+05 -1.46389873e+04  1.44341609e+05]\n",
      " [-4.20591133e+04 -3.75848169e+03  2.74709750e+05]\n",
      " [-2.97724969e+05  1.58633578e+05  1.57842266e+05]\n",
      " [-3.54544781e+05  3.81927661e+03  1.66437391e+05]\n",
      " [ 2.16094828e+05 -2.86577281e+05  1.98748625e+05]\n",
      " [ 3.10929344e+05 -3.22546250e+04  2.16782484e+05]\n",
      " [-2.84211469e+05 -1.06651562e+05  3.71071562e+05]\n",
      " [ 3.10236219e+05 -8.92132344e+04  2.45994203e+05]\n",
      " [ 6.31268906e+04  1.73312016e+05  1.95856922e+05]\n",
      " [ 1.18730180e+05 -3.28342719e+05  2.89776281e+05]\n",
      " [-1.31241859e+05 -2.43428328e+05  4.05363031e+05]\n",
      " [-1.37337683e+03 -2.58189109e+05  1.95965422e+05]\n",
      " [-1.39962797e+05 -1.14595562e+05  2.10190688e+05]\n",
      " [-4.32381797e+04 -3.63102109e+04  3.70397562e+05]\n",
      " [ 2.56699578e+05  4.74952832e+03  1.88530359e+05]\n",
      " [ 2.77905371e+04 -2.79361312e+05  2.59249688e+05]\n",
      " [-2.79122094e+05 -7.01538281e+04  2.92370219e+05]\n",
      " [ 1.28928148e+05  2.82712625e+05  3.84545844e+05]\n",
      " [-3.02944469e+05  3.81848312e+05  2.41434844e+05]\n",
      " [-1.54244906e+05 -3.03361426e+04  3.42851000e+05]\n",
      " [ 8.84519141e+04 -2.48248797e+05  2.61076891e+05]\n",
      " [ 3.09470605e+04 -2.53783891e+05  1.18258359e+05]\n",
      " [ 1.47006719e+05  6.37940500e+05  2.16089438e+05]\n",
      " [ 7.19042562e+05  1.19860516e+05  1.51571812e+05]\n",
      " [ 7.43072125e+05  1.25683375e+05  3.19984938e+05]\n",
      " [ 5.01070250e+05 -4.71627594e+05  2.40229734e+05]\n",
      " [-3.02841281e+05  6.30385938e+05  1.97442609e+05]\n",
      " [-4.93379469e+05  4.90137844e+05  1.78882688e+05]\n",
      " [-3.08612250e+05 -5.36989312e+05  2.71136844e+05]], shape=(64, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "matrix, rhs = make_matrix(real_coords[:,:,:,:2], times_reg, mask_qs)\n",
    "theta_flat, phi_flat, t0_flat = lin_solve(matrix, rhs) # (bs,)\n",
    "phi_flat = tf.where( phi_flat>0, phi_flat, 3.1415*2 + phi_flat  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_rec = ev_params[:num,2]/180*3.1415\n",
    "phi_rec = ev_params[:num,3]/180*3.1415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07382543 0.08574376 0.1362938  0.14861791 0.11598436]\n",
      "[1.5707964 1.5707964 1.5707964 1.5707964 1.5707964]\n"
     ]
    }
   ],
   "source": [
    "print(theta_rec[:5])\n",
    "print(theta_flat[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03144362 0.03644769 0.08272914 0.10213749 0.06431471]\n",
      "[1.9238552 3.1939151 3.0090413 5.631687  6.281422 ]\n"
     ]
    }
   ],
   "source": [
    "print(phi_rec[:5])\n",
    "print(phi_flat[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_ext_ch = t0_flat[:,tf.newaxis,tf.newaxis]\n",
    "nx = - tf.math.sin(theta_flat)[:,tf.newaxis,tf.newaxis] * tf.math.cos(phi_flat)[:,tf.newaxis,tf.newaxis]\n",
    "ny = - tf.math.sin(theta_flat)[:,tf.newaxis,tf.newaxis] * tf.math.sin(phi_flat)[:,tf.newaxis,tf.newaxis]\n",
    "# nz = tf.math.cos(theta_flat)[:,tf.newaxis,tf.newaxis]\n",
    "a = tf.concat((nx,ny), axis=-1)\n",
    "# a = tf.concat((a,nz), axis=-1)\n",
    "a = tf.expand_dims( a, axis=1 )\n",
    "\n",
    "t_rec = t0_ext_ch + tf.math.reduce_sum( a*real_coords[:,:,:,:2], axis=-1 )\n",
    "t_rec = t_rec*mask_in[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-1161116.     -518197.2     622288.6     756613.1    1883906.\n",
      "     3783.5     107255.66    702980.3    1088205.5     330695.5\n",
      "  1019143.75   -418883.53   1817196.1     515853.44  -1082180.8\n",
      "  -205966.78    289950.72   -536171.6     847886.6    -773915.25\n",
      " -1083733.4    -142969.25   1289158.4     539117.1   -1044828.4\n",
      "  -775178.94    937199.2   -1584282.4    -851070.25   -179951.69\n",
      "  2566506.8    -261711.1    1985467.8     -72707.19     31145.375\n",
      "    95842.75   -160384.31   1147741.4    1055798.      534625.\n",
      "   812207.44    381007.44    471021.03   -121462.75     97817.05\n",
      "   276702.       -5303.875    31524.688   -94011.03    410987.8\n",
      "   332435.44   -398104.12    -66837.78    915750.25   -139409.38\n",
      "   -87842.125  -137385.88    -73083.44     52549.812  2163841.2\n",
      "  -224016.75    -22118.875   -44708.062   162990.62 ], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "diff = times_reg[:,:,:,0]*mask_qs[:,:,:,0]-t_rec\n",
    "print(tf.reduce_sum(diff, axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.10118219 0.1089315  0.20253925 0.35319355 0.11736246 0.25390136\n",
      " 0.08409789 0.2064849  0.1975056  0.34670734 0.26725373 0.10407462\n",
      " 0.08335411 0.3183393  1.0593617  0.2990111  0.0831734  0.20299003\n",
      " 0.04378579 0.15864886 0.04055079 0.13750985 0.12065328 0.2244104\n",
      " 0.34522566 0.12849776 0.1275013  0.21244767 0.5705006  0.07331727\n",
      " 0.5690793  0.09886026 0.20316596 0.08108567 0.36974138 0.154049\n",
      " 0.3673324  0.10409182 0.11426502 0.7217716  0.12717076 0.2597414\n",
      " 0.21678165 0.4350091  0.19198945 0.19539404 0.05313609 0.32304367\n",
      " 0.12754351 0.14420262 0.6141158  1.7418705  0.17269109 0.21208388\n",
      " 0.15527344 0.10184619 0.05864263 0.28793675 0.26712793 0.40014043\n",
      " 0.12685588 0.06280586 1.6369988  0.123521  ], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "diff = tf.math.abs(times_reg[:,:,:,0]*mask_qs[:,:,:,0]-t_rec)\n",
    "print(tf.reduce_sum(diff, axis=(1,2))/tf.reduce_sum(mask_qs[:,:,:,0], axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.20959783 0.2491904  0.29979244 0.46025634 0.22600068 0.5615435\n",
      " 0.21208236 0.3837521  0.30413944 0.5434806  0.39171636 0.22527264\n",
      " 0.25122324 0.49563184 0.8944951  0.5041607  0.20514372 0.30792856\n",
      " 0.21039082 0.2998451  0.21259886 0.3003548  0.2123761  0.29086298\n",
      " 0.65118724 0.30259255 0.26660118 0.29097    0.6283361  0.25731772\n",
      " 1.111545   0.29811305 0.44951534 0.23422359 0.48266825 0.35602495\n",
      " 0.45696634 0.19953333 0.30399272 0.9878     0.24123335 0.39388442\n",
      " 0.32432398 0.7449414  0.49496242 0.3955919  0.19893165 0.5378073\n",
      " 0.2446798  0.27781522 0.8566028  1.7153467  0.36108875 0.38223526\n",
      " 0.3163981  0.4180154  0.18116035 0.45855767 0.49706036 0.61922365\n",
      " 0.31778312 0.22721304 1.4874202  0.2791607 ], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "diff = tf.math.abs(times_flat[:,:,:,0]*mask_qs[:,:,:,0]-t_rec)\n",
    "print(tf.reduce_sum(diff, axis=(1,2))/tf.reduce_sum(mask_qs[:,:,:,0], axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_ext_ch = t0_flat[:,tf.newaxis,tf.newaxis]\n",
    "nx =  tf.math.sin(theta_rec)[:,tf.newaxis,tf.newaxis] * tf.math.sin(phi_rec)[:,tf.newaxis,tf.newaxis]\n",
    "ny =  tf.math.sin(theta_rec)[:,tf.newaxis,tf.newaxis] * tf.math.cos(phi_rec)[:,tf.newaxis,tf.newaxis]\n",
    "# nz =  tf.math.cos(theta_rec)[:,tf.newaxis,tf.newaxis] \n",
    "a = tf.concat((nx,ny), axis=-1)\n",
    "# a = tf.concat((a,nz), axis=-1)\n",
    "a = tf.expand_dims( a, axis=1)\n",
    "t_rec = t0_ext_ch + tf.math.reduce_sum( a*real_coords[:,:,:,:2], axis=-1 )\n",
    "t_rec = t_rec*mask_in[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_const(data):\n",
    "    #shape b,6,6\n",
    "    m=tf.reduce_min(data,axis=(1,2))[:,tf.newaxis,tf.newaxis]\n",
    "    return tf.where(data!=0,data-m,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6, 6), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.3234228 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.68942094,  0.33484584,\n",
       "         -0.01837397,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.29531562,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.6517277 ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -1.1545774 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.6689595 , -0.69463134,\n",
       "          0.50055885,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.12741184,  0.8078254 ,\n",
       "          1.4880164 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_const(times_flat[:,:,:,0]*mask_qs[:,:,:,0])[:2] - norm_const(t_rec[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 6, 6, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 6, 6), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.41621315,\n",
       "         -0.73963594,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.05021497, -0.40479004,\n",
       "         -0.7580099 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.44432035,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.08790815,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -1.4708228 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.985205  , -0.31625763,\n",
       "          0.18431342,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.18883362,  0.49157992,\n",
       "          1.1717709 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.26905638,\n",
       "         -0.17842177,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.5884346 , -1.0410454 ,\n",
       "         -1.492809  , -1.9397963 ],\n",
       "        [ 0.        ,  0.        ,  0.        , -2.3506851 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.2639135 , -0.83244276,\n",
       "         -1.3941238 ,  0.        ],\n",
       "        [ 0.7962773 ,  0.2358827 , -0.32848322, -0.8964984 ,\n",
       "         -1.4567797 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         -1.7016932 ,  0.        ],\n",
       "        [ 0.        ,  0.4001247 , -0.15689635, -0.72271585,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.25435483, -0.30874178,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.10990578,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.8747072 ,\n",
       "          0.00924218,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -1.9245172 ,\n",
       "         -1.0329835 , -0.13490102],\n",
       "        [ 0.        ,  0.        , -3.927849  , -2.9821937 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -4.931716  ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.1041671 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.38412252,  0.08217731,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.39100796,  0.10649823,\n",
       "          0.551934  ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.07963884,\n",
       "          0.5596837 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  1.184387  ,  0.8703865 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.28091317, -0.02587697, -0.32229054,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -1.5609161 ,\n",
       "         -1.8771646 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.33232075,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  1.3611561 ,  0.3423819 , -0.6498286 ,\n",
       "         -1.6500868 ,  0.        ],\n",
       "        [ 0.        ,  1.042393  ,  0.03698015, -0.9751173 ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.42081335, -0.38890865,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.42865658, -0.3951117 ,\n",
       "         -0.36239487,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.43705073, -0.40190315,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(times_flat[:,:,:,0]*mask_qs[:,:,:,0])[:10] - t_rec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.33780378 0.8385002  1.0697865  0.5298703  0.50468665 1.4404854\n",
      " 0.4413312  0.9344003  0.69621634 0.42085034 0.359538   0.4988852\n",
      " 1.2250637  0.37252808 1.3646446  0.9700557  0.6308561  1.3745422\n",
      " 0.37079042 0.6060708  0.93294686 0.83640426 0.30973452 0.52382714\n",
      " 0.42700285 0.21177241 0.5346812  0.3681648  0.74378145 0.8309407\n",
      " 0.92892736 0.3893106  0.44841275 0.22688846 0.655149   0.5135215\n",
      " 0.72955054 0.19569325 0.24424267 0.80545944 0.3943959  0.61710435\n",
      " 0.5402409  0.68076485 0.18714333 0.4297542  0.26822567 0.70215064\n",
      " 0.26185256 0.83002716 1.0199969  1.7097206  0.8266812  0.49381268\n",
      " 0.59338075 0.873635   0.53900224 0.2777193  1.0295748  0.59572536\n",
      " 1.4585447  0.48960736 1.6701157  0.7591628 ], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "diff = tf.math.abs(times_reg[:,:,:,0]*mask_qs[:,:,:,0]-t_rec)\n",
    "print(tf.reduce_sum(diff, axis=(1,2))/tf.reduce_sum(mask_qs[:,:,:,0], axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.4144418  0.8014639  1.1228926  0.77555025 0.52206177 1.9772637\n",
      " 0.2824037  1.0203224  0.79878306 0.404977   0.39734146 0.4504902\n",
      " 1.1336699  0.5583589  1.2209958  1.252962   0.58148557 1.2225046\n",
      " 0.27580988 0.4619863  0.96692324 0.76496804 0.33120808 0.65389425\n",
      " 0.6020886  0.30313373 0.60106033 0.4298907  0.88247347 0.99033386\n",
      " 1.161687   0.39440703 0.7113342  0.2695825  0.7543537  0.73342264\n",
      " 0.72287977 0.23195603 0.36368838 1.3027338  0.517268   0.6511093\n",
      " 0.7337783  1.1655794  0.51238716 0.50492024 0.3254206  0.7915652\n",
      " 0.28385034 0.76051813 0.9902329  1.6200744  0.69342405 0.67377955\n",
      " 0.54791224 0.9576268  0.48820874 0.24434505 1.0329417  0.6980211\n",
      " 1.4824531  0.47211945 1.1423812  0.89389646], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "diff = tf.math.abs(times_flat[:,:,:,0]*mask_qs[:,:,:,0]-t_rec)\n",
    "print(tf.reduce_sum(diff, axis=(1,2))/tf.reduce_sum(mask_qs[:,:,:,0], axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6, 6), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.6609411 ,\n",
       "         -0.93200696,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.14764751, -0.10905427,\n",
       "         -0.3656123 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.40684628,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  1.2547005 ,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.97166836,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.29058582,  0.31625763,\n",
       "          0.34871757,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.3783737 , -0.34408203,\n",
       "         -0.31136653,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rec[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S_800 reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_flat = theta_flat[:,tf.newaxis, tf.newaxis]\n",
    "phi_flat = phi_flat[:,tf.newaxis, tf.newaxis]\n",
    "t0_flat = t0_flat[:,tf.newaxis,tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eta(theta):\n",
    "    \n",
    "    x = theta*180.0/3.1415\n",
    "    \n",
    "    e1 = 3.97 - 1.79*(tf.math.abs(1.0/(tf.math.abs(tf.math.cos(theta))+1e-6)) - 1.0)\n",
    "    e2 = ((((((-1.71299934e-10*x + 4.23849411e-08)*x -3.76192000e-06)*x\n",
    "               + 1.35747298e-04)*x -2.18241567e-03)*x + 1.18960682e-02)*x\n",
    "             + 3.70692527e+00)\n",
    "    res = tf.where(x<62.7,e1,e2)\n",
    "    # valid ???\n",
    "    #res = tf.where(res>0,res,0)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f84b46ae550>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = np.arange(0., 3.141/2, 0.1)\n",
    "es = get_eta(ts)\n",
    "\n",
    "plt.plot(ts,es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rm = tf.constant([0.09])\n",
    "R1 = tf.constant([1.])\n",
    "\n",
    "def get_profile(r, eta):\n",
    "\n",
    "    res = tf.math.pow(((r+1e-6)/Rm),-1.2) * tf.math.pow((1+r/Rm), -(eta-1.2)) * tf.math.pow(1.+(tf.math.pow(r,2)/R1/R1),-0.6)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_x = tf.constant([[0.8]])\n",
    "\n",
    "# r should be centered at shower's core\n",
    "# normed so that ldf(800m)=1\n",
    "def get_normed_ldf(r, eta):\n",
    "    \n",
    "    norm = get_profile(R_x, eta)\n",
    "    ldf = get_profile(r, eta)\n",
    "    \n",
    "    if tf.math.reduce_any( tf.math.is_nan( norm )):\n",
    "            print('ldf norm Nan') \n",
    "    if tf.math.reduce_any( tf.math.is_nan( ldf )):\n",
    "            print('ldf ldf Nan') \n",
    "    \n",
    "    return ldf/norm\n",
    "    #return tf.math.divide_no_nan(ldf,norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_min = tf.constant([[0.3]])\n",
    "s_max = tf.constant([[1.8]])\n",
    "\n",
    "Det_Area = 3.0\n",
    "\n",
    "def get_S_norm_raw(qs, coords, r_core, theta, phi, mask, eta):\n",
    "    # calculate distance to shower core\n",
    "    cent_coords = coords - r_core\n",
    "    proj_to_n = tf.math.sin(theta)*( tf.math.cos(phi)*cent_coords[:,:,:,0] + tf.math.sin(phi)*cent_coords[:,:,:,1] )\n",
    "    dist_core = tf.math.reduce_sum( tf.math.pow(cent_coords,2), axis=(3) ) - tf.math.pow(proj_to_n,2)\n",
    "    dist_core = tf.where( dist_core>0, tf.math.sqrt( dist_core ), 0. )\n",
    "    # mask for distances\n",
    "    mask_dist = tf.where( tf.math.logical_and(dist_core>s_min,dist_core<s_max), 1., 0. )\n",
    "    mask = mask[:,:,:,0]*mask_dist\n",
    "    #mask = mask[:,:,:,0]\n",
    "    \n",
    "    mq = get_measured_ldf(mask, qs)\n",
    "    eq = get_expected_ldf(dist_core, eta, mask)\n",
    "    \n",
    "    return mq, eq\n",
    "\n",
    "def get_measured_ldf(mask, qs):\n",
    "\n",
    "    return tf.math.reduce_sum( qs*mask, axis=(1,2) ) / Det_Area\n",
    "\n",
    "def get_expected_ldf(dist_core, eta, mask):\n",
    "    \n",
    "    exp_qs = get_normed_ldf(dist_core, eta)*mask\n",
    "    if tf.math.reduce_any( tf.math.is_nan( exp_qs )):\n",
    "            print('exp_qs Nan eval')\n",
    "    \n",
    "    return tf.math.reduce_sum( exp_qs, axis=(1,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_flat = get_eta(theta_flat)\n",
    "mq, eq = get_S_norm_raw(qs_in[:,:,:,0], real_coords[:,:,:,:2], r_core_0, theta_flat, phi_flat, mask_qs, eta_flat)\n",
    "S_norm_ch = mq/(eq+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f84b45cfeb8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(mq,eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc_th = ev_params[:num,8:9][:,tf.newaxis]/180*3.1415\n",
    "# mc_phi = ev_params[:num,9:10][:,tf.newaxis]/180*3.1415\n",
    "# print(mc_th.shape,mc_phi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta_mc = get_eta(mc_th)\n",
    "# mq, eq = get_S_norm_raw(qs_in[:,:,:,0], real_coords[:,:,:,:2], np.zeros_like(real_coords)[:,0:1,0:1,:2], mc_th, mc_phi, mask_qs, eta_mc)\n",
    "# S_norm_ch = mq/(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(mq,eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full time reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_ivanov(theta, rescale):\n",
    "    \n",
    "    theta_degr = theta/3.1415*180.\n",
    "    \n",
    "    r1 = 3.3836 - 0.01848*theta_degr\n",
    "    r2 = (0.6511268210e-4*(theta_degr-.2614963683))*(theta_degr*theta_degr-134.7902422*theta_degr+4558.524091)\n",
    "    r3 = tf.math.exp(-3.2e-2*theta_degr + 2.0)\n",
    "    \n",
    "    a_ivanov = tf.where( theta_degr<25.0, r1, r2 )\n",
    "    a_ivanov = tf.where( theta_degr>35.0, r3, a_ivanov )\n",
    "    \n",
    "    if rescale:\n",
    "        a_ivanov *= 1.3\n",
    "    \n",
    "    return a_ivanov\n",
    "\n",
    "def get_S_norm(dist_core, mask, qs, eta):\n",
    "    # mask for distances\n",
    "    mask_dist = tf.where( tf.math.logical_and(dist_core>s_min,dist_core<s_max), 1., 0. )\n",
    "    mask = mask*mask_dist\n",
    "    if tf.math.reduce_any( tf.math.is_nan( mask )):\n",
    "            print('mask Nan eval')\n",
    "    \n",
    "    mq = get_measured_ldf(mask, qs)\n",
    "    if tf.math.reduce_any( mq==0 ):\n",
    "            print('mq =0 eval')\n",
    "    eq = get_expected_ldf(dist_core, eta, mask)\n",
    "    if tf.math.reduce_any( tf.math.is_nan( eq )):\n",
    "            print('eq Nan eval')\n",
    "    \n",
    "    return mq/(eq+1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed to - in plane\n",
    "R_L = 0.03\n",
    "R_error = 0.15\n",
    "\n",
    "def get_lins_t(r, s):\n",
    "    return 0.67*tf.math.pow((1 + r/R_L), 1.5)*tf.math.pow(s+1e-8, -0.5)\n",
    "\n",
    "def get_exp_time(t0, theta, phi, coords, mask, r_core, qs, rescale):\n",
    "    # flat\n",
    "    t_plane = t0 - tf.math.sin(theta)*( tf.math.cos(phi)*coords[:,:,:,0] + tf.math.sin(phi)*coords[:,:,:,1] ) - tf.math.cos(theta)*coords[:,:,:,2]\n",
    "    if tf.math.reduce_any( tf.math.is_nan( t_plane )):\n",
    "            print('t_plane Nan eval')\n",
    "    ## curvature\n",
    "    # get S_800\n",
    "    cent_coords = coords[:,:,:,:2] - r_core\n",
    "    proj_to_n = tf.math.sin(theta)*( tf.math.cos(phi)*cent_coords[:,:,:,0] + tf.math.sin(phi)*cent_coords[:,:,:,1] ) + tf.math.cos(theta)*coords[:,:,:,2]\n",
    "    dist_core = tf.math.reduce_sum( tf.math.pow(cent_coords,2), axis=(3) ) - tf.math.pow(proj_to_n,2)\n",
    "    dist_core = tf.where( dist_core>0, tf.math.sqrt( dist_core ), 0. )\n",
    "    # IS THIS ALSO NESSASARY?\n",
    "    dist_core = tf.where( dist_core>R_error, dist_core, R_error )\n",
    "    eta = get_eta(theta)\n",
    "    if tf.math.reduce_any( tf.math.is_nan( eta )):\n",
    "            print('eta Nan eval')\n",
    "    S_norm = get_S_norm(dist_core, mask, qs, eta)[:,tf.newaxis, tf.newaxis]\n",
    "    if tf.math.reduce_any( tf.math.is_nan( S_norm )):\n",
    "            print('S_norm Nan eval')\n",
    "    if tf.math.reduce_any( S_norm<0 ):\n",
    "            print('S_norm <0 eval')\n",
    "    if tf.math.reduce_any( S_norm==0 ):\n",
    "            print('S_norm =0 eval')\n",
    "    # get curv parameters\n",
    "    a_ivanov = get_a_ivanov(theta, rescale)\n",
    "    if tf.math.reduce_any( tf.math.is_nan( a_ivanov )):\n",
    "            print('a_ivanov Nan eval')\n",
    "    aprime = a_ivanov/tf.math.sqrt(S_norm)\n",
    "    if tf.math.reduce_any( tf.math.is_nan( aprime )):\n",
    "            print('aprime Nan eval')\n",
    "    s_prof = get_normed_ldf(dist_core, theta)\n",
    "    if tf.math.reduce_any( tf.math.is_nan( s_prof )):\n",
    "            print('s_prof Nan eval')\n",
    "    # time due to curvature\n",
    "    t_curv = aprime*get_lins_t( dist_core, s_prof )\n",
    "    if tf.math.reduce_any( tf.math.is_nan( t_curv )):\n",
    "            print('s_prof Nan eval')\n",
    "    \n",
    "    return ( t_plane + t_curv * 1e-3*time2dist )*mask # nsec -> mks -> km "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = get_exp_time(t0_flat, theta_flat, phi_flat, real_coords[:,:,:,:3], mask_qs[:,:,:,0], r_core_sat_0, qs_in[:,:,:,0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_err = 30.\n",
    "t_err_resc = tf.math.pow( 1e-3*time2dist, 2 )\n",
    "\n",
    "def get_linsley_s(r, S):\n",
    "    return 1.3*0.29*tf.math.pow((1 + r/R_L), 1.5)*pow(S+1e-6, -0.3)\n",
    "\n",
    "def get_t_err(aprime, S_norm, r, eta):\n",
    "    s_prof = get_profile(r, eta)\n",
    "    lin_s = get_linsley_s( r, S_norm*s_prof )\n",
    "    t_s = aprime*tf.math.sqrt(S_norm)*lin_s\n",
    "    return (t0_err*t0_err + t_s*t_s) * t_err_resc # ns^2 -> mks^2 -> km^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_expected_q(t_0, thetta, phi, coords, r_core, S_norm):\n",
    "    \n",
    "    t_plane = t_0 - tf.math.sin(thetta)*( tf.math.cos(phi)*coords[:,:,:,0] + tf.math.sin(phi)*coords[:,:,:,1] )\n",
    "    if tf.math.reduce_any( tf.math.is_nan( t_plane )):\n",
    "        print('plane Nan in')\n",
    "    cent_coords = coords[:,:,:,:2] - r_core\n",
    "    if tf.math.reduce_any( tf.math.is_nan( cent_coords )):\n",
    "        print('r_core Nan in')  \n",
    "    proj_to_n = tf.math.sin(thetta)*( tf.math.cos(phi)*cent_coords[:,:,:,0] + tf.math.sin(phi)*cent_coords[:,:,:,1] ) + tf.math.cos(thetta)*coords[:,:,:,2]\n",
    "    if tf.math.reduce_any( tf.math.is_nan( proj_to_n )):\n",
    "        print('proj Nan in')\n",
    "    dist_core = tf.math.reduce_sum( tf.math.pow(cent_coords,2), axis=(3) ) - tf.math.pow(proj_to_n,2)\n",
    "    dist_core = tf.where( dist_core>0, tf.math.sqrt( dist_core ), 0. )\n",
    "    # IS THIS ALSO NESSASARY?\n",
    "    dist_core = tf.where( dist_core>R_error, dist_core, R_error )\n",
    "    if tf.math.reduce_any( tf.math.is_nan( dist_core )):\n",
    "        print('dist_core Nan in')\n",
    "    eta = get_eta(thetta)\n",
    "    s_prof = get_normed_ldf(dist_core, eta)\n",
    "    s_expt = S_norm*s_prof\n",
    "    return s_expt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descendent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial: aprime, S_800\n",
    "def init_vars(theta, phi, coords, mask, r_core, qs, rescale):\n",
    "    \n",
    "    cent_coords = coords[:,:,:,:2] - r_core\n",
    "    proj_to_n = tf.math.sin(theta)*( tf.math.cos(phi)*cent_coords[:,:,:,0] + tf.math.sin(phi)*cent_coords[:,:,:,1] )\n",
    "    dist_core = tf.math.sqrt( tf.math.reduce_sum( tf.math.pow(cent_coords,2), axis=(3) ) - tf.math.pow(proj_to_n,2) )\n",
    "    eta = get_eta(theta)\n",
    "    S_norm = get_S_norm(dist_core, mask, qs, eta)[:,tf.newaxis, tf.newaxis]\n",
    "    # get curv parameters\n",
    "    a_ivanov = get_a_ivanov(theta, rescale)\n",
    "    aprime = a_ivanov/tf.math.sqrt(S_norm)\n",
    "    \n",
    "    return aprime, S_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprime_init, S_norm_init = init_vars( theta_flat, phi_flat, real_coords[:,:,:,:3], mask_qs[:,:,:,0], r_core_sat_0, qs_in[:,:,:,0], True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 1, 1), dtype=float32, numpy=\n",
       "array([[[3.470824  ]],\n",
       "\n",
       "       [[2.2276804 ]],\n",
       "\n",
       "       [[2.0998054 ]],\n",
       "\n",
       "       [[3.3438952 ]],\n",
       "\n",
       "       [[2.5654454 ]],\n",
       "\n",
       "       [[1.9159312 ]],\n",
       "\n",
       "       [[2.5877671 ]],\n",
       "\n",
       "       [[1.6522739 ]],\n",
       "\n",
       "       [[1.8890294 ]],\n",
       "\n",
       "       [[3.163911  ]],\n",
       "\n",
       "       [[4.649707  ]],\n",
       "\n",
       "       [[2.6174002 ]],\n",
       "\n",
       "       [[1.8294905 ]],\n",
       "\n",
       "       [[1.9089719 ]],\n",
       "\n",
       "       [[2.7317376 ]],\n",
       "\n",
       "       [[1.9112891 ]],\n",
       "\n",
       "       [[2.7152843 ]],\n",
       "\n",
       "       [[2.742577  ]],\n",
       "\n",
       "       [[2.4908638 ]],\n",
       "\n",
       "       [[1.5166676 ]],\n",
       "\n",
       "       [[1.9393828 ]],\n",
       "\n",
       "       [[1.8904628 ]],\n",
       "\n",
       "       [[2.561862  ]],\n",
       "\n",
       "       [[1.8264297 ]],\n",
       "\n",
       "       [[1.8421997 ]],\n",
       "\n",
       "       [[2.6971772 ]],\n",
       "\n",
       "       [[6.5654693 ]],\n",
       "\n",
       "       [[3.3169296 ]],\n",
       "\n",
       "       [[1.702898  ]],\n",
       "\n",
       "       [[2.018732  ]],\n",
       "\n",
       "       [[1.3839806 ]],\n",
       "\n",
       "       [[1.742648  ]],\n",
       "\n",
       "       [[3.3739145 ]],\n",
       "\n",
       "       [[2.761984  ]],\n",
       "\n",
       "       [[2.3989627 ]],\n",
       "\n",
       "       [[2.7272167 ]],\n",
       "\n",
       "       [[1.8493538 ]],\n",
       "\n",
       "       [[2.86537   ]],\n",
       "\n",
       "       [[3.1377292 ]],\n",
       "\n",
       "       [[1.9217573 ]],\n",
       "\n",
       "       [[4.012393  ]],\n",
       "\n",
       "       [[1.7685806 ]],\n",
       "\n",
       "       [[2.887332  ]],\n",
       "\n",
       "       [[3.4807584 ]],\n",
       "\n",
       "       [[2.0219626 ]],\n",
       "\n",
       "       [[3.174729  ]],\n",
       "\n",
       "       [[2.2556667 ]],\n",
       "\n",
       "       [[1.653352  ]],\n",
       "\n",
       "       [[3.1654382 ]],\n",
       "\n",
       "       [[2.0557725 ]],\n",
       "\n",
       "       [[0.7676899 ]],\n",
       "\n",
       "       [[0.69574505]],\n",
       "\n",
       "       [[3.054368  ]],\n",
       "\n",
       "       [[3.0065763 ]],\n",
       "\n",
       "       [[1.9545273 ]],\n",
       "\n",
       "       [[1.7413619 ]],\n",
       "\n",
       "       [[2.921282  ]],\n",
       "\n",
       "       [[2.796264  ]],\n",
       "\n",
       "       [[1.9072796 ]],\n",
       "\n",
       "       [[1.3785237 ]],\n",
       "\n",
       "       [[1.8354114 ]],\n",
       "\n",
       "       [[1.9108193 ]],\n",
       "\n",
       "       [[2.9188647 ]],\n",
       "\n",
       "       [[2.8262026 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprime_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_qs = get_expected_q(t0_flat, theta_flat, phi_flat, real_coords[:,:,:,:3], r_core_sat_0, S_norm_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.17748055  0.05192861  0.        ]\n",
      " [ 0.          0.          0.4145333  11.053725    0.06990292  0.        ]\n",
      " [ 0.          0.          0.          0.17242149  0.          0.        ]\n",
      " [ 0.          0.          0.02238672  0.          0.          0.        ]], shape=(6, 6), dtype=float32)\n",
      "[[ 0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        1.24868   0.477705  0.      ]\n",
      " [ 0.        0.        8.35528  10.5188    0.698082  0.      ]\n",
      " [ 0.        0.        0.        3.40935   0.        0.      ]\n",
      " [ 0.        0.        1.22881   0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "print((exp_qs*mask_qs[0,:,:,0])[0])\n",
    "print(qs_in[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_var = []\n",
    "\n",
    "for p in [t0_flat, theta_flat, phi_flat, r_core_sat_0, aprime_init, S_norm_init]:\n",
    "    opt_params_var.append( tf.Variable(p, True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_params_var = []\n",
    "\n",
    "# for p in [t0_flat, theta_mc, phi_mc, r_core_sat_0, aprime_init, S_norm_init]:\n",
    "#     opt_params_var.append( tf.Variable(p, True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite to individual loss?\n",
    "\n",
    "def chi2_loss(predicted, real, mask, error):\n",
    "        \n",
    "    if tf.math.reduce_any( tf.math.is_nan( predicted )):\n",
    "        print('loss Nan in')\n",
    "    if tf.math.reduce_any( tf.math.is_nan( error )):\n",
    "        print('error Nan in')\n",
    "    n_points = tf.math.reduce_sum( mask, axis=(1,2), keepdims=False )\n",
    "    chi2 = tf.math.reduce_sum( (predicted-real)*(predicted-real)/error*mask, axis=(1,2) )\n",
    "    if tf.math.reduce_any( tf.math.is_nan( chi2 )):\n",
    "        print('loss Nan out')\n",
    "\n",
    "    return chi2, n_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chi2_accumulate(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self, n_pars):\n",
    "        self.n_pars = n_pars\n",
    "        super().__init__()\n",
    "        \n",
    "    def __call__(self, losses, n_points):\n",
    "        \n",
    "        loss = tf.stack(losses, axis=0)\n",
    "        loss = tf.math.reduce_sum( loss )\n",
    "        \n",
    "        n_ps = tf.stack(n_points, axis=0)\n",
    "        n_ps = tf.math.reduce_sum( n_ps )\n",
    "        \n",
    "        n_ps = n_ps - self.n_pars\n",
    "        n_ps = tf.where( n_ps>0, n_ps, 1. )\n",
    "        \n",
    "        return loss/n_ps\n",
    "    \n",
    "loss_fn = chi2_accumulate(7) # 7 for joint fit, 4 for geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logPua(n, nbar):\n",
    "    \n",
    "    mask_nbar_0 = tf.where( nbar< 1e-40, True, False )\n",
    "    mask_n_0 = tf.where( n>1e-40, True, False )\n",
    "    mask_n_0 = tf.logical_and( mask_nbar_0, mask_n_0 )\n",
    "    \n",
    "    mask_n = tf.where( n<1e-20, True, False )\n",
    "    mask_n = tf.logical_and( ~mask_nbar_0, mask_n )\n",
    "    \n",
    "    mask_res = tf.logical_and( ~mask_nbar_0, ~mask_n )\n",
    "    \n",
    "    res = tf.zeros_like(n)\n",
    "    \n",
    "    res = tf.where( mask_n_0, -1.*1e-6, 0. )\n",
    "            \n",
    "    res = tf.where( mask_n,  -2*nbar, res )\n",
    "\n",
    "    res = tf.where( mask_res, 2*(n*tf.math.log(nbar/(n+1e-8)) + (n - nbar)), res )\n",
    "    \n",
    "    return res\n",
    "\n",
    "def logPau_loss(q_reg, q_exp, mask):\n",
    "    \n",
    "    loss = tf.math.reduce_sum( (-0.4*logPua(q_reg*Det_Area, q_exp*Det_Area))*mask, axis=(1,2) )\n",
    "    if tf.math.reduce_any( tf.math.is_nan( loss )):\n",
    "            print('loss Nan eval')  \n",
    "    n_ps = tf.math.reduce_sum( mask, axis=(1,2), keepdims=False )\n",
    "    return loss, n_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# - in t plane\n",
    "def opt_step(opt_params, coords, mask, qs, do_print):\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "        tape.watch( opt_params )\n",
    "\n",
    "        # time reco\n",
    "        t_plane = opt_params[0] - tf.math.sin(opt_params[1])*( tf.math.cos(opt_params[2])*coords[:,:,:,0] + tf.math.sin(opt_params[2])*coords[:,:,:,1] )\n",
    "        if tf.math.reduce_any( tf.math.is_nan( t_plane )):\n",
    "            print('plane Nan in')\n",
    "        cent_coords = coords[:,:,:,:2] - opt_params[3]\n",
    "        if tf.math.reduce_any( tf.math.is_nan( cent_coords )):\n",
    "            print('r_core Nan in')  \n",
    "        proj_to_n = tf.math.sin(opt_params[1])*( tf.math.cos(opt_params[2])*cent_coords[:,:,:,0] + tf.math.sin(opt_params[2])*cent_coords[:,:,:,1] ) + tf.math.cos(opt_params[1])*coords[:,:,:,2]\n",
    "        if tf.math.reduce_any( tf.math.is_nan( proj_to_n )):\n",
    "            print('proj Nan in')\n",
    "        dist_core = tf.math.reduce_sum( tf.math.pow(cent_coords,2), axis=(3) ) - tf.math.pow(proj_to_n,2)\n",
    "        if tf.math.reduce_any( dist_core<-0.1 ):\n",
    "            print('dist_core <-0.1 eval')\n",
    "        dist_core = tf.where( dist_core>0, tf.math.sqrt( dist_core ), 0. )\n",
    "        # IS THIS ALSO NESSASARY?\n",
    "        dist_core = tf.where( dist_core>R_error, dist_core, R_error )\n",
    "        if tf.math.reduce_any( tf.math.is_nan( dist_core )):\n",
    "            print('dist_core Nan in')\n",
    "        eta = get_eta(opt_params[1])\n",
    "        s_prof = get_normed_ldf(dist_core, eta)\n",
    "        if tf.math.reduce_any( tf.math.is_nan( s_prof )):\n",
    "            print('plane Nan in')\n",
    "        # time due to curvature\n",
    "        t_curv = opt_params[4]*get_lins_t( dist_core, s_prof )\n",
    "        if tf.math.reduce_any( tf.math.is_nan( t_curv )):\n",
    "            print('curve Nan in')\n",
    "\n",
    "        # geometry\n",
    "        # WHAT IS S REALLY IN R. CODE? and is this really nessesary?\n",
    "        mask_q = tf.where( qs>0.1, 1., 0. )\n",
    "        mask_t = mask_q * mask\n",
    "        t_res = (t_plane + t_curv * 1e-3*time2dist )*mask_t         \n",
    "        t_err = get_t_err( opt_params[4], opt_params[5], dist_core, eta )\n",
    "        loss_t, n_ps_t = chi2_loss( t_res, times_reg[:,:,:,0], mask_t, t_err )\n",
    "        #print(loss_t)\n",
    "        \n",
    "        # Q\n",
    "        s_expt = opt_params[5]*s_prof\n",
    "        if tf.math.reduce_any( tf.math.is_nan( s_expt )):\n",
    "            print('s_expt Nan in')\n",
    "        # q2\n",
    "        mask_q2 = tf.where( s_expt>4., 1., 0 ) # error\n",
    "        mask_q2 = mask_q2*mask_t\n",
    "        if tf.math.reduce_any( tf.math.is_nan( mask_q2 )):\n",
    "            print('mask_q2 Nan in')\n",
    "        error_q2 = ( 2*qs/Det_Area + tf.math.pow( 0.15*qs, 2 ) + 1e-6 )\n",
    "        if tf.math.reduce_any( tf.math.is_nan( error_q2 )):\n",
    "            print('error_q2 Nan in')\n",
    "        loss_q2, n_ps_q2 = chi2_loss( s_expt, qs, mask_q2, error_q2 )\n",
    "        print(loss_q2[1])\n",
    "        print(s_expt[1] - qs[1])\n",
    "        print( s_expt[1], qs[1])\n",
    "        # q3\n",
    "        mask_q3 = tf.where( s_expt<4., 1., 0 )\n",
    "        mask_q3 = mask_t*mask_q3\n",
    "        loss_q3, n_ps_q3 = logPau_loss( qs, s_expt, mask_q3 )\n",
    "        \n",
    "        # accumulate\n",
    "        loss = loss_fn( [loss_t,loss_q2,loss_q3], [n_ps_t,n_ps_q2,n_ps_q3] )\n",
    "        #print(loss)\n",
    "        mask_big_a = tf.where( opt_params[4]>2., 1., 0. )\n",
    "        reg_a = mask_big_a*( opt_params[4]-2. )*100.\n",
    "        loss += reg_a\n",
    "\n",
    "        #n_ps_q2 = tf.where( n_ps_q2-7.>0., n_ps_q2-7, 1.  )\n",
    "        #print(tf.math.reduce_sum( loss_t/n_ps_q2 ), tf.math.reduce_sum( loss_q2/n_ps_q2 )   , end='\\r')\n",
    "        if do_print:\n",
    "            print(tf.math.reduce_sum( loss_t ), tf.math.reduce_sum( loss_q2 ), tf.math.reduce_sum( loss_q3 ), end='\\r')\n",
    "           # print( tf.math.reduce_sum( loss_q3 ) , tf.math.reduce_sum( n_ps_q3 )   , end='\\r' )\n",
    "        #print(loss, end='\\r')\n",
    "        \n",
    "    # update weights\n",
    "    grads = tape.gradient(loss, opt_params)\n",
    "    for j,g in enumerate(grads):\n",
    "        if tf.math.reduce_any( tf.math.is_nan( g )):\n",
    "            print('grads Nan, '+str(j))\n",
    "#     grads[1] = 5.0*grads[1]\n",
    "#     grads[2] = 5.0*grads[2]\n",
    "    #print(grads)\n",
    "    optimizer.apply_gradients( zip(grads, opt_params) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(64, 1, 1) dtype=float32, numpy=\n",
       " array([[[0.18313918]],\n",
       " \n",
       "        [[0.22105971]],\n",
       " \n",
       "        [[0.34821752]],\n",
       " \n",
       "        [[0.39385   ]],\n",
       " \n",
       "        [[0.16991688]],\n",
       " \n",
       "        [[0.05262369]],\n",
       " \n",
       "        [[0.13758725]],\n",
       " \n",
       "        [[0.32672206]],\n",
       " \n",
       "        [[0.3066352 ]],\n",
       " \n",
       "        [[0.41110653]],\n",
       " \n",
       "        [[0.36466753]],\n",
       " \n",
       "        [[0.1930675 ]],\n",
       " \n",
       "        [[0.16350907]],\n",
       " \n",
       "        [[0.47811392]],\n",
       " \n",
       "        [[0.7552005 ]],\n",
       " \n",
       "        [[0.33892918]],\n",
       " \n",
       "        [[0.19417721]],\n",
       " \n",
       "        [[0.28491703]],\n",
       " \n",
       "        [[0.13565637]],\n",
       " \n",
       "        [[0.23687716]],\n",
       " \n",
       "        [[0.18609358]],\n",
       " \n",
       "        [[0.24654938]],\n",
       " \n",
       "        [[0.16917393]],\n",
       " \n",
       "        [[0.26276648]],\n",
       " \n",
       "        [[0.43663564]],\n",
       " \n",
       "        [[0.29451743]],\n",
       " \n",
       "        [[0.2272598 ]],\n",
       " \n",
       "        [[0.28225508]],\n",
       " \n",
       "        [[0.497523  ]],\n",
       " \n",
       "        [[0.19749312]],\n",
       " \n",
       "        [[1.2533567 ]],\n",
       " \n",
       "        [[0.227085  ]],\n",
       " \n",
       "        [[0.41420203]],\n",
       " \n",
       "        [[0.11385632]],\n",
       " \n",
       "        [[0.51786315]],\n",
       " \n",
       "        [[0.26965597]],\n",
       " \n",
       "        [[0.3577411 ]],\n",
       " \n",
       "        [[0.20267127]],\n",
       " \n",
       "        [[0.16643612]],\n",
       " \n",
       "        [[0.894632  ]],\n",
       " \n",
       "        [[0.20422818]],\n",
       " \n",
       "        [[0.4144071 ]],\n",
       " \n",
       "        [[0.30546576]],\n",
       " \n",
       "        [[0.5051996 ]],\n",
       " \n",
       "        [[0.5370292 ]],\n",
       " \n",
       "        [[0.36964947]],\n",
       " \n",
       "        [[0.15465076]],\n",
       " \n",
       "        [[0.4010523 ]],\n",
       " \n",
       "        [[0.24496537]],\n",
       " \n",
       "        [[0.26279798]],\n",
       " \n",
       "        [[0.91348076]],\n",
       " \n",
       "        [[1.3730458 ]],\n",
       " \n",
       "        [[0.21765216]],\n",
       " \n",
       "        [[0.41536573]],\n",
       " \n",
       "        [[0.2559181 ]],\n",
       " \n",
       "        [[0.20307004]],\n",
       " \n",
       "        [[0.15644816]],\n",
       " \n",
       "        [[0.15182224]],\n",
       " \n",
       "        [[0.5003743 ]],\n",
       " \n",
       "        [[0.4088672 ]],\n",
       " \n",
       "        [[0.2647529 ]],\n",
       " \n",
       "        [[0.21124487]],\n",
       " \n",
       "        [[1.3544188 ]],\n",
       " \n",
       "        [[0.18997867]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(64, 1, 1) dtype=float32, numpy=\n",
       " array([[[0.8121814 ]],\n",
       " \n",
       "        [[0.65408677]],\n",
       " \n",
       "        [[0.84191763]],\n",
       " \n",
       "        [[0.52959126]],\n",
       " \n",
       "        [[0.66981965]],\n",
       " \n",
       "        [[0.46815076]],\n",
       " \n",
       "        [[0.6098847 ]],\n",
       " \n",
       "        [[0.37968978]],\n",
       " \n",
       "        [[0.40986392]],\n",
       " \n",
       "        [[0.2378638 ]],\n",
       " \n",
       "        [[0.34851614]],\n",
       " \n",
       "        [[0.6328583 ]],\n",
       " \n",
       "        [[0.60423714]],\n",
       " \n",
       "        [[0.45926145]],\n",
       " \n",
       "        [[0.40925008]],\n",
       " \n",
       "        [[0.35418436]],\n",
       " \n",
       "        [[0.589983  ]],\n",
       " \n",
       "        [[0.61187345]],\n",
       " \n",
       "        [[0.69748795]],\n",
       " \n",
       "        [[0.6706891 ]],\n",
       " \n",
       "        [[0.57888764]],\n",
       " \n",
       "        [[0.54071903]],\n",
       " \n",
       "        [[0.60280544]],\n",
       " \n",
       "        [[0.26902744]],\n",
       " \n",
       "        [[0.28514388]],\n",
       " \n",
       "        [[0.54765576]],\n",
       " \n",
       "        [[0.45141712]],\n",
       " \n",
       "        [[0.44912776]],\n",
       " \n",
       "        [[0.2764178 ]],\n",
       " \n",
       "        [[0.4963712 ]],\n",
       " \n",
       "        [[0.8575573 ]],\n",
       " \n",
       "        [[0.5514129 ]],\n",
       " \n",
       "        [[0.27725807]],\n",
       " \n",
       "        [[0.59564096]],\n",
       " \n",
       "        [[0.66266376]],\n",
       " \n",
       "        [[0.4900338 ]],\n",
       " \n",
       "        [[0.6720241 ]],\n",
       " \n",
       "        [[0.6444569 ]],\n",
       " \n",
       "        [[0.5157389 ]],\n",
       " \n",
       "        [[0.56381077]],\n",
       " \n",
       "        [[0.46995404]],\n",
       " \n",
       "        [[0.7470033 ]],\n",
       " \n",
       "        [[0.4438163 ]],\n",
       " \n",
       "        [[0.2715664 ]],\n",
       " \n",
       "        [[0.18310839]],\n",
       " \n",
       "        [[0.5272418 ]],\n",
       " \n",
       "        [[0.6859467 ]],\n",
       " \n",
       "        [[0.26811594]],\n",
       " \n",
       "        [[0.48397782]],\n",
       " \n",
       "        [[0.5547647 ]],\n",
       " \n",
       "        [[1.5707964 ]],\n",
       " \n",
       "        [[1.5707964 ]],\n",
       " \n",
       "        [[0.32074717]],\n",
       " \n",
       "        [[0.40534952]],\n",
       " \n",
       "        [[0.5978517 ]],\n",
       " \n",
       "        [[0.4646562 ]],\n",
       " \n",
       "        [[0.6260204 ]],\n",
       " \n",
       "        [[0.61866224]],\n",
       " \n",
       "        [[0.43005058]],\n",
       " \n",
       "        [[0.5801942 ]],\n",
       " \n",
       "        [[0.6255243 ]],\n",
       " \n",
       "        [[0.5800554 ]],\n",
       " \n",
       "        [[0.15829939]],\n",
       " \n",
       "        [[0.5307451 ]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(64, 1, 1) dtype=float32, numpy=\n",
       " array([[[2.3758223 ]],\n",
       " \n",
       "        [[4.198601  ]],\n",
       " \n",
       "        [[0.49112618]],\n",
       " \n",
       "        [[1.9791083 ]],\n",
       " \n",
       "        [[2.426582  ]],\n",
       " \n",
       "        [[5.0500984 ]],\n",
       " \n",
       "        [[3.5635247 ]],\n",
       " \n",
       "        [[0.48094448]],\n",
       " \n",
       "        [[1.9905576 ]],\n",
       " \n",
       "        [[1.0829496 ]],\n",
       " \n",
       "        [[0.66197175]],\n",
       " \n",
       "        [[1.9808301 ]],\n",
       " \n",
       "        [[3.8192477 ]],\n",
       " \n",
       "        [[1.8733511 ]],\n",
       " \n",
       "        [[0.3229701 ]],\n",
       " \n",
       "        [[5.133383  ]],\n",
       " \n",
       "        [[0.79457706]],\n",
       " \n",
       "        [[6.2707267 ]],\n",
       " \n",
       "        [[5.089992  ]],\n",
       " \n",
       "        [[4.293888  ]],\n",
       " \n",
       "        [[1.8999649 ]],\n",
       " \n",
       "        [[5.8643093 ]],\n",
       " \n",
       "        [[5.7134643 ]],\n",
       " \n",
       "        [[5.0800514 ]],\n",
       " \n",
       "        [[4.813633  ]],\n",
       " \n",
       "        [[5.095542  ]],\n",
       " \n",
       "        [[2.475176  ]],\n",
       " \n",
       "        [[0.11064745]],\n",
       " \n",
       "        [[5.827672  ]],\n",
       " \n",
       "        [[3.9222293 ]],\n",
       " \n",
       "        [[2.3518953 ]],\n",
       " \n",
       "        [[2.8934703 ]],\n",
       " \n",
       "        [[5.5742493 ]],\n",
       " \n",
       "        [[0.3377822 ]],\n",
       " \n",
       "        [[3.494048  ]],\n",
       " \n",
       "        [[1.6316782 ]],\n",
       " \n",
       "        [[4.3935304 ]],\n",
       " \n",
       "        [[0.4389492 ]],\n",
       " \n",
       "        [[5.038578  ]],\n",
       " \n",
       "        [[4.0567393 ]],\n",
       " \n",
       "        [[3.2099953 ]],\n",
       " \n",
       "        [[2.1587718 ]],\n",
       " \n",
       "        [[5.5345902 ]],\n",
       " \n",
       "        [[0.06378552]],\n",
       " \n",
       "        [[4.3736954 ]],\n",
       " \n",
       "        [[5.3782983 ]],\n",
       " \n",
       "        [[5.1460075 ]],\n",
       " \n",
       "        [[2.4608138 ]],\n",
       " \n",
       "        [[3.34139   ]],\n",
       " \n",
       "        [[4.6331058 ]],\n",
       " \n",
       "        [[3.1654034 ]],\n",
       " \n",
       "        [[5.507583  ]],\n",
       " \n",
       "        [[4.1523266 ]],\n",
       " \n",
       "        [[0.6879098 ]],\n",
       " \n",
       "        [[4.5075226 ]],\n",
       " \n",
       "        [[2.9265363 ]],\n",
       " \n",
       "        [[1.3085799 ]],\n",
       " \n",
       "        [[6.2481203 ]],\n",
       " \n",
       "        [[0.30810142]],\n",
       " \n",
       "        [[2.6650476 ]],\n",
       " \n",
       "        [[5.863156  ]],\n",
       " \n",
       "        [[2.5112956 ]],\n",
       " \n",
       "        [[2.806327  ]],\n",
       " \n",
       "        [[4.386522  ]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(64, 1, 1, 2) dtype=float32, numpy=\n",
       " array([[[[-0.13557288,  0.287459  ]]],\n",
       " \n",
       " \n",
       "        [[[-0.1373117 , -0.18429497]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01779432, -0.05242745]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03709867,  0.08123933]]],\n",
       " \n",
       " \n",
       "        [[[-0.07913389,  0.11355855]]],\n",
       " \n",
       " \n",
       "        [[[ 0.36963895, -0.5779316 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06768455,  0.07666608]]],\n",
       " \n",
       " \n",
       "        [[[-0.01671986,  0.12267559]]],\n",
       " \n",
       " \n",
       "        [[[-0.24290451,  0.2373524 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.02363295, -0.04328264]]],\n",
       " \n",
       " \n",
       "        [[[-0.1261831 ,  0.1360702 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01841521, -0.15023254]]],\n",
       " \n",
       " \n",
       "        [[[ 0.19885339,  0.19276924]]],\n",
       " \n",
       " \n",
       "        [[[-0.25930676, -0.25816727]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06793019,  0.0368754 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.33994088, -0.27345288]]],\n",
       " \n",
       " \n",
       "        [[[ 0.04234466,  0.02986594]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00920578, -0.05670976]]],\n",
       " \n",
       " \n",
       "        [[[-0.01702672,  0.10618307]]],\n",
       " \n",
       " \n",
       "        [[[-0.15509409, -0.1282063 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.0548223 ,  0.07524732]]],\n",
       " \n",
       " \n",
       "        [[[ 0.11120529,  0.14419498]]],\n",
       " \n",
       " \n",
       "        [[[ 0.14425491, -0.03878262]]],\n",
       " \n",
       " \n",
       "        [[[-0.25276455, -0.19314453]]],\n",
       " \n",
       " \n",
       "        [[[ 0.04689056, -0.159586  ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00443696,  0.06453911]]],\n",
       " \n",
       " \n",
       "        [[[-0.22653149,  0.21787837]]],\n",
       " \n",
       " \n",
       "        [[[-0.07356144, -0.01771202]]],\n",
       " \n",
       " \n",
       "        [[[ 0.22390853, -0.33026025]]],\n",
       " \n",
       " \n",
       "        [[[-0.3227232 , -0.39679605]]],\n",
       " \n",
       " \n",
       "        [[[-0.32559198, -0.19727834]]],\n",
       " \n",
       " \n",
       "        [[[ 0.07208475, -0.12338305]]],\n",
       " \n",
       " \n",
       "        [[[-0.03183206, -0.17887592]]],\n",
       " \n",
       " \n",
       "        [[[ 0.10141971,  0.02025921]]],\n",
       " \n",
       " \n",
       "        [[[-0.02454504,  0.02083363]]],\n",
       " \n",
       " \n",
       "        [[[ 0.07970313,  0.02484807]]],\n",
       " \n",
       " \n",
       "        [[[ 0.2700522 , -0.26120746]]],\n",
       " \n",
       " \n",
       "        [[[-0.01164512,  0.11913276]]],\n",
       " \n",
       " \n",
       "        [[[-0.12938745,  0.05679917]]],\n",
       " \n",
       " \n",
       "        [[[-0.36150834, -0.21378185]]],\n",
       " \n",
       " \n",
       "        [[[ 0.10962296,  0.19249742]]],\n",
       " \n",
       " \n",
       "        [[[-0.08350874, -0.07769907]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0270484 ,  0.00675157]]],\n",
       " \n",
       " \n",
       "        [[[ 0.20879889,  0.05059948]]],\n",
       " \n",
       " \n",
       "        [[[-0.21381584,  0.21906361]]],\n",
       " \n",
       " \n",
       "        [[[-0.02839248,  0.08048902]]],\n",
       " \n",
       " \n",
       "        [[[-0.00780294,  0.15755123]]],\n",
       " \n",
       " \n",
       "        [[[ 0.09713215,  0.06731091]]],\n",
       " \n",
       " \n",
       "        [[[ 0.09374649,  0.04051979]]],\n",
       " \n",
       " \n",
       "        [[[-0.2971405 ,  0.07320206]]],\n",
       " \n",
       " \n",
       "        [[[-0.25276375,  0.30571738]]],\n",
       " \n",
       " \n",
       "        [[[ 0.21447508,  0.31599653]]],\n",
       " \n",
       " \n",
       "        [[[-0.06597622, -0.05599395]]],\n",
       " \n",
       " \n",
       "        [[[-0.01799748,  0.02300875]]],\n",
       " \n",
       " \n",
       "        [[[ 0.15392785, -0.01946695]]],\n",
       " \n",
       " \n",
       "        [[[-0.0236712 , -0.19606268]]],\n",
       " \n",
       " \n",
       "        [[[-0.14432856, -0.11305612]]],\n",
       " \n",
       " \n",
       "        [[[-0.22594015, -0.01867986]]],\n",
       " \n",
       " \n",
       "        [[[-0.03243522,  0.19292274]]],\n",
       " \n",
       " \n",
       "        [[[ 0.53054297, -0.3616602 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.0429377 , -0.06173515]]],\n",
       " \n",
       " \n",
       "        [[[-0.08320484, -0.0231635 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00660143, -0.08174665]]],\n",
       " \n",
       " \n",
       "        [[[-0.10159582, -0.05010989]]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(64, 1, 1) dtype=float32, numpy=\n",
       " array([[[3.470824  ]],\n",
       " \n",
       "        [[2.2276804 ]],\n",
       " \n",
       "        [[2.0998054 ]],\n",
       " \n",
       "        [[3.3438952 ]],\n",
       " \n",
       "        [[2.5654454 ]],\n",
       " \n",
       "        [[1.9159312 ]],\n",
       " \n",
       "        [[2.5877671 ]],\n",
       " \n",
       "        [[1.6522739 ]],\n",
       " \n",
       "        [[1.8890294 ]],\n",
       " \n",
       "        [[3.163911  ]],\n",
       " \n",
       "        [[4.649707  ]],\n",
       " \n",
       "        [[2.6174002 ]],\n",
       " \n",
       "        [[1.8294905 ]],\n",
       " \n",
       "        [[1.9089719 ]],\n",
       " \n",
       "        [[2.7317376 ]],\n",
       " \n",
       "        [[1.9112891 ]],\n",
       " \n",
       "        [[2.7152843 ]],\n",
       " \n",
       "        [[2.742577  ]],\n",
       " \n",
       "        [[2.4908638 ]],\n",
       " \n",
       "        [[1.5166676 ]],\n",
       " \n",
       "        [[1.9393828 ]],\n",
       " \n",
       "        [[1.8904628 ]],\n",
       " \n",
       "        [[2.561862  ]],\n",
       " \n",
       "        [[1.8264297 ]],\n",
       " \n",
       "        [[1.8421997 ]],\n",
       " \n",
       "        [[2.6971772 ]],\n",
       " \n",
       "        [[6.5654693 ]],\n",
       " \n",
       "        [[3.3169296 ]],\n",
       " \n",
       "        [[1.702898  ]],\n",
       " \n",
       "        [[2.018732  ]],\n",
       " \n",
       "        [[1.3839806 ]],\n",
       " \n",
       "        [[1.742648  ]],\n",
       " \n",
       "        [[3.3739145 ]],\n",
       " \n",
       "        [[2.761984  ]],\n",
       " \n",
       "        [[2.3989627 ]],\n",
       " \n",
       "        [[2.7272167 ]],\n",
       " \n",
       "        [[1.8493538 ]],\n",
       " \n",
       "        [[2.86537   ]],\n",
       " \n",
       "        [[3.1377292 ]],\n",
       " \n",
       "        [[1.9217573 ]],\n",
       " \n",
       "        [[4.012393  ]],\n",
       " \n",
       "        [[1.7685806 ]],\n",
       " \n",
       "        [[2.887332  ]],\n",
       " \n",
       "        [[3.4807584 ]],\n",
       " \n",
       "        [[2.0219626 ]],\n",
       " \n",
       "        [[3.174729  ]],\n",
       " \n",
       "        [[2.2556667 ]],\n",
       " \n",
       "        [[1.653352  ]],\n",
       " \n",
       "        [[3.1654382 ]],\n",
       " \n",
       "        [[2.0557725 ]],\n",
       " \n",
       "        [[0.7676899 ]],\n",
       " \n",
       "        [[0.69574505]],\n",
       " \n",
       "        [[3.054368  ]],\n",
       " \n",
       "        [[3.0065763 ]],\n",
       " \n",
       "        [[1.9545273 ]],\n",
       " \n",
       "        [[1.7413619 ]],\n",
       " \n",
       "        [[2.921282  ]],\n",
       " \n",
       "        [[2.796264  ]],\n",
       " \n",
       "        [[1.9072796 ]],\n",
       " \n",
       "        [[1.3785237 ]],\n",
       " \n",
       "        [[1.8354114 ]],\n",
       " \n",
       "        [[1.9108193 ]],\n",
       " \n",
       "        [[2.9188647 ]],\n",
       " \n",
       "        [[2.8262026 ]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(64, 1, 1) dtype=float32, numpy=\n",
       " array([[[0.38970858]],\n",
       " \n",
       "        [[1.6891835 ]],\n",
       " \n",
       "        [[0.95475066]],\n",
       " \n",
       "        [[1.1191038 ]],\n",
       " \n",
       "        [[1.2022682 ]],\n",
       " \n",
       "        [[3.8061695 ]],\n",
       " \n",
       "        [[1.4720552 ]],\n",
       " \n",
       "        [[5.5031395 ]],\n",
       " \n",
       "        [[4.120399  ]],\n",
       " \n",
       "        [[1.6558025 ]],\n",
       " \n",
       "        [[0.71037334]],\n",
       " \n",
       "        [[1.3226668 ]],\n",
       " \n",
       "        [[3.0057113 ]],\n",
       " \n",
       "        [[3.8751934 ]],\n",
       " \n",
       "        [[1.9711968 ]],\n",
       " \n",
       "        [[4.1874924 ]],\n",
       " \n",
       "        [[1.4328895 ]],\n",
       " \n",
       "        [[1.301047  ]],\n",
       " \n",
       "        [[1.1522937 ]],\n",
       " \n",
       "        [[3.4289522 ]],\n",
       " \n",
       "        [[2.9107687 ]],\n",
       " \n",
       "        [[3.4092958 ]],\n",
       " \n",
       "        [[1.5406253 ]],\n",
       " \n",
       "        [[4.8646398 ]],\n",
       " \n",
       "        [[4.729186  ]],\n",
       " \n",
       "        [[1.6455739 ]],\n",
       " \n",
       "        [[0.33034545]],\n",
       " \n",
       "        [[1.2971574 ]],\n",
       " \n",
       "        [[5.567793  ]],\n",
       " \n",
       "        [[3.284677  ]],\n",
       " \n",
       "        [[2.0752988 ]],\n",
       " \n",
       "        [[3.9032073 ]],\n",
       " \n",
       "        [[1.417562  ]],\n",
       " \n",
       "        [[1.3587896 ]],\n",
       " \n",
       "        [[1.411485  ]],\n",
       " \n",
       "        [[1.8192515 ]],\n",
       " \n",
       "        [[2.2949662 ]],\n",
       " \n",
       "        [[1.057688  ]],\n",
       " \n",
       "        [[1.3101312 ]],\n",
       " \n",
       "        [[3.101338  ]],\n",
       " \n",
       "        [[0.86581975]],\n",
       " \n",
       "        [[1.9061471 ]],\n",
       " \n",
       "        [[1.7201171 ]],\n",
       " \n",
       "        [[1.3370721 ]],\n",
       " \n",
       "        [[4.2057548 ]],\n",
       " \n",
       "        [[1.2482249 ]],\n",
       " \n",
       "        [[1.4658636 ]],\n",
       " \n",
       "        [[5.9401345 ]],\n",
       " \n",
       "        [[1.3635342 ]],\n",
       " \n",
       "        [[2.7795434 ]],\n",
       " \n",
       "        [[0.49326774]],\n",
       " \n",
       "        [[0.60055685]],\n",
       " \n",
       "        [[1.678518  ]],\n",
       " \n",
       "        [[1.631844  ]],\n",
       " \n",
       "        [[2.692923  ]],\n",
       " \n",
       "        [[4.6277084 ]],\n",
       " \n",
       "        [[1.088764  ]],\n",
       " \n",
       "        [[1.2207942 ]],\n",
       " \n",
       "        [[3.9835532 ]],\n",
       " \n",
       "        [[5.737585  ]],\n",
       " \n",
       "        [[2.7631457 ]],\n",
       " \n",
       "        [[2.9875007 ]],\n",
       " \n",
       "        [[2.0515702 ]],\n",
       " \n",
       "        [[1.562465  ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.03,\n",
    "#                                                    decay_steps=num_pictures // batch_size,\n",
    "# 20 -> 10 -> 5                                                   decay_rate=0.98)\n",
    "lr = 0.001*20\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 2.1493698e+02  2.1493698e+02  2.1493698e+02  2.1493698e+02\n",
      "   2.1493698e+02  2.1493698e+02]\n",
      " [ 2.1493698e+02  2.1493698e+02  2.1493698e+02  2.1493698e+02\n",
      "   2.1493698e+02  2.1493698e+02]\n",
      " [ 2.1493698e+02  2.1493698e+02  2.1493698e+02 -3.9137506e-01\n",
      "   2.1493698e+02  2.1493698e+02]\n",
      " [ 2.1493698e+02  2.1493698e+02 -9.3362331e-03  7.6841881e+01\n",
      "  -5.7079554e-01  2.1493698e+02]\n",
      " [ 2.1493698e+02  2.1493698e+02 -3.7798041e-01 -1.5164089e-01\n",
      "   7.7969670e-02  2.1493698e+02]\n",
      " [ 2.1493698e+02  2.1493698e+02  2.1493698e+02  2.1493698e+02\n",
      "   2.1493698e+02  2.1493698e+02]], shape=(6, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[214.93698    214.93698    214.93698    214.93698    214.93698\n",
      "  214.93698   ]\n",
      " [214.93698    214.93698    214.93698    214.93698    214.93698\n",
      "  214.93698   ]\n",
      " [214.93698    214.93698    214.93698      0.5385639  214.93698\n",
      "  214.93698   ]\n",
      " [214.93698    214.93698      3.5156739   76.84188      3.0801044\n",
      "  214.93698   ]\n",
      " [214.93698    214.93698      0.26231557   1.3353992    1.7963496\n",
      "  214.93698   ]\n",
      " [214.93698    214.93698    214.93698    214.93698    214.93698\n",
      "  214.93698   ]], shape=(6, 6), dtype=float32) [[0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.       0.       0.      ]\n",
      " [0.       0.       0.       0.929939 0.       0.      ]\n",
      " [0.       0.       3.52501  0.       3.6509   0.      ]\n",
      " [0.       0.       0.640296 1.48704  1.71838  0.      ]\n",
      " [0.       0.       0.       0.       0.       0.      ]]\n",
      "tf.Tensor(487.5088, shape=(), dtype=float32) tf.Tensor(84.3124, shape=(), dtype=float32) tf.Tensor(581.20715, shape=(), dtype=float32)\r"
     ]
    }
   ],
   "source": [
    "n_iter = 1#00*5\n",
    "\n",
    "for i in range(n_iter):\n",
    "    if (i % 10)==0:\n",
    "        do_print = True\n",
    "    else:\n",
    "        do_print = False\n",
    "    opt_step(opt_params_var, real_coords[:,:,:,:3], mask_qs[:,:,:,0], qs_in[:,:,:,0], do_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.011171   -1.5779757   0.        ]\n",
      " [ 0.          0.          0.28233847 -0.46215162 -0.9434997   0.        ]\n",
      " [ 0.          0.          0.          0.2461326   0.          0.        ]\n",
      " [ 0.          0.          1.938757    0.          0.          0.        ]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(get_exp_time(opt_params_var[0], opt_params_var[1], opt_params_var[2], real_coords[:,:,:,:3], mask_qs[:,:,:,0], opt_params_var[3], qs_in[:,:,:,0], True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.84391576 -1.4614884   0.        ]\n",
      " [ 0.          0.          0.1873703  -0.41221467 -0.9338535   0.        ]\n",
      " [ 0.          0.          0.          0.09143671  0.          0.        ]\n",
      " [ 0.          0.          1.680337    0.          0.          0.        ]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(times_reg[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          1.2915611   0.47381693  0.        ]\n",
      " [ 0.          0.          6.2207932  10.411403    0.50290734  0.        ]\n",
      " [ 0.          0.          0.          1.6918875   0.          0.        ]\n",
      " [ 0.          0.          0.7876729   0.          0.          0.        ]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "exp_qs = get_expected_q(opt_params_var[0], opt_params_var[1], opt_params_var[2], real_coords[:,:,:,:3], opt_params_var[3], opt_params_var[5])\n",
    "print((exp_qs*mask_qs[:,:,:,0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        1.24868   0.477705  0.      ]\n",
      " [ 0.        0.        8.35528  10.5188    0.698082  0.      ]\n",
      " [ 0.        0.        0.        3.40935   0.        0.      ]\n",
      " [ 0.        0.        1.22881   0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "print(qs_in[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09745841 0.9524284 2.4096746 [ 0.23714636 -0.13665302] 1.8078693 3.5997863\n"
     ]
    }
   ],
   "source": [
    "print( opt_params_var[0][0,0,0].numpy(), opt_params_var[1][0,0,0].numpy(), opt_params_var[2][0,0,0].numpy(), opt_params_var[3][0,0,0].numpy(), opt_params_var[4][0,0,0].numpy(), opt_params_var[5][0,0,0].numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18313916 0.8121814 2.3758225 [-0.13557288  0.287459  ] 3.4708233 0.38970876\n"
     ]
    }
   ],
   "source": [
    "print( t0_flat[0,0,0].numpy(), theta_flat[0,0,0].numpy(), phi_flat[0,0,0].numpy(), r_core_sat_0[0][0,0].numpy(), aprime_init[0,0,0].numpy(), S_norm_init[0,0,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reco\n",
      "[54.57174  45.831844 38.005898 55.07941  45.976967 40.88763  47.093403\n",
      " 48.879654 46.436817 32.473167]\n",
      "real\n",
      "[31.2504  33.2834  32.8449   8.73218  8.12228 33.138   32.6748  30.5449\n",
      " 36.2028  32.472  ]\n",
      "diff\n",
      "[4.0702212e-01 2.1900523e-01 9.0073705e-02 8.0888790e-01 6.6066945e-01\n",
      " 1.3525259e-01 2.5164461e-01 3.1999242e-01 1.7861205e-01 2.0325184e-05]\n"
     ]
    }
   ],
   "source": [
    "n_sh = 10\n",
    "print('reco')\n",
    "print(opt_params_var[1][:n_sh,0,0].numpy()*180/3.1415)\n",
    "print('real')\n",
    "print(ev_params[:n_sh,2])\n",
    "print('diff')\n",
    "print(opt_params_var[1][:n_sh,0,0].numpy()-ev_params[:n_sh,2]/180*3.1415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.4096746   4.2147694   0.97440463  1.43057     2.6435318   4.8470473\n",
      "  3.3234558  -0.7694808   1.7205485  -1.0595884 ]\n",
      "[1.9971561  4.76426    1.352386   2.9889452  1.5452079  1.7927319\n",
      " 1.9820247  1.3915989  0.96158695 3.2810874 ]\n"
     ]
    }
   ],
   "source": [
    "print(opt_params_var[2][:n_sh,0,0].numpy())\n",
    "print((ev_params[:n_sh,3])/180*3.1415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5715872  0.5715872  0.5715872  0.1144808  0.1144808  0.56433034\n",
      " 0.56433034 0.56433034 0.56433034 0.56433034]\n",
      "[1.9501734 4.5760136 1.3769177 3.1316044 1.2647138 1.8036051 1.9725829\n",
      " 1.5060874 0.8844911 3.2893949]\n"
     ]
    }
   ],
   "source": [
    "print(ev_params[:n_sh,8]/180*3.1415)\n",
    "print(ev_params[:n_sh,9]/180*3.1415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor: shape=(6, 6, 1), dtype=float32, numpy=\narray([[[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.]]], dtype=float32)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, tight_layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m) )\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m axs\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mtimes_flat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_qs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, times_reg[i][mask_qs[i]])\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:906\u001b[0m, in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    901\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     idx\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    904\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[1;32m    905\u001b[0m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor: shape=(6, 6, 1), dtype=float32, numpy=\narray([[[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.]]], dtype=float32)>"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, tight_layout=True, figsize=(6, 4) )\n",
    "    plt.grid(True)\n",
    "    axs.scatter(times_flat[i][mask_qs[i]], times_reg[i][mask_qs[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(h5f,'r') as hf:\n",
    "    chi2 = hf['pr-q3-9yr/gp'][:num,6]\n",
    "\n",
    "print(chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_exp_time_reco(t0, theta, phi, coords, mask, r_core, qs, a_curv, S_norm, rescale):\n",
    "#     # flat\n",
    "#     t_plane = t0 - tf.math.sin(theta)*( tf.math.cos(phi)*coords[:,:,:,0] + tf.math.sin(phi)*coords[:,:,:,1] ) - tf.math.cos(theta)*coords[:,:,:,2]\n",
    "#     if tf.math.reduce_any( tf.math.is_nan( t_plane )):\n",
    "#             print('t_plane Nan eval')\n",
    "#     ## curvature\n",
    "#     eta = get_eta(theta)\n",
    "#     if tf.math.reduce_any( tf.math.is_nan( eta )):\n",
    "#             print('eta Nan eval')\n",
    "            \n",
    "#     a_ivanov = get_a_ivanov(theta, rescale)\n",
    "#     if tf.math.reduce_any( tf.math.is_nan( a_ivanov )):\n",
    "#             print('a_ivanov Nan eval')\n",
    "#     aprime = a_ivanov/tf.math.sqrt(S_norm)\n",
    "#     if tf.math.reduce_any( tf.math.is_nan( aprime )):\n",
    "#             print('aprime Nan eval')\n",
    "#     s_prof = get_normed_ldf(dist_core, theta)\n",
    "#     if tf.math.reduce_any( tf.math.is_nan( s_prof )):\n",
    "#             print('s_prof Nan eval')\n",
    "#     # time due to curvature\n",
    "#     t_curv = aprime*get_lins_t( dist_core, s_prof )\n",
    "#     if tf.math.reduce_any( tf.math.is_nan( t_curv )):\n",
    "#             print('s_prof Nan eval')\n",
    "    \n",
    "#     return ( t_plane + t_curv * 1e-3*time2dist )*mask # nsec -> mks -> km "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no t0\n",
    "# t_0_mc = tf.constant([[[0.]]])\n",
    "# # angles\n",
    "# theta_mc = ev_params[:num,2][:,tf.newaxis, tf.newaxis]/180*3.1415\n",
    "# phi_mc = ev_params[:num,3][:,tf.newaxis, tf.newaxis]/180*3.1415\n",
    "# # aprime\n",
    "# with h5.File(h5f,'r') as hf:\n",
    "#     a_iv = hf['pr-q3-9yr/gp'][:num,6][:,tf.newaxis, tf.newaxis]\n",
    "#     s_iv = hf['pr-q3-9yr/gp'][:num,2][:,tf.newaxis, tf.newaxis]\n",
    "    \n",
    "# aprime_reco = a_iv/tf.sqrt(s_iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(aprime_reco[:5], a_iv[:5], s_iv[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
